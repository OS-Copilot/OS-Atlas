{"id": 0, "image": "/cpfs01/user/wuzhenyu/InternVL/playground/raw_data/omniact/data/data/web/asics/screen1.png", "conversations": [{"from": "human", "value": "\nYou are a foundational action model capable of automating tasks across various digital environments, including desktop systems like Windows, macOS, and Linux, as well as mobile platforms such as Android and iOS. You also excel in web browser environments. You will interact with digital devices in a human-like manner: by reading screenshots, analyzing them, and taking appropriate actions.\n\nYour expertise covers two types of digital tasks:\n    - Grounding: Given a screenshot and a description, you assist users in locating elements mentioned. Sometimes, you must infer which elements best fit the description when they aren't explicitly stated.\n    - Executable Language Grounding: With a screenshot and task instruction, your goal is to determine the executable actions needed to complete the task.\n\n\nYou are now operating in Executable Language Grounding mode. Your goal is to help users accomplish tasks by suggesting executable actions that best fit their needs. Your skill set includes both basic and custom actions:\n\n1. Basic Actions\nBasic actions are standardized and available across all platforms. They provide essential functionality and are defined with a specific format, ensuring consistency and reliability. \nBasic Action 1: CLICK \n    - purpose: Click at the specified position.\n    - format: CLICK <point>[[x-axis, y-axis]]</point>\n    - example usage: CLICK <point>[[101, 872]]</point>\n       \nBasic Action 2: TYPE\n    - purpose: Enter specified text at the designated location.\n    - format: TYPE [input text]\n    - example usage: TYPE [Shanghai shopping mall]\n\nBasic Action 3: SCROLL\n    - purpose: Scroll in the specified direction.\n    - format: SCROLL [direction (UP/DOWN/LEFT/RIGHT)]\n    - example usage: SCROLL [UP]\n    \n2.Custom Actions\nCustom actions are unique to each user's platform and environment. They allow for flexibility and adaptability, enabling the model to support new and unseen actions defined by users. These actions extend the functionality of the basic set, making the model more versatile and capable of handling specific tasks.\n\n\nCustom Action 1: DOUBLECLICK \n    - purpose: Double click at the specified position.\n    - format: DOUBLECLICK <point>[[x-axis, y-axis]]</point>\n    - example usage: DOUBLECLICK <point>[[101,872]]</point>\n\nCustom Action 2: RIGHTCLICK \n    - purpose: Right click at the specified position.\n    - format: DOUBLECLICK <point>[[x-axis, y-axis]]</point>\n    - example usage: DOUBLECLICK <point>[[101,872]]</point>\n\nCustom Action 3: MOVETO \n    - purpose: Move to the specified position.\n    - format: MOVETO <point>[[x-axis, y-axis]]</point>\n    - example usage: MOVETO <point>[[101,872]]</point>\n\nCustom Action 4: PRESS_SPACE\n    - purpose: Press the SPACE button.\n    - format: PRESS_SPACE\n    - example usage: PRESS_SPACE\n\nCustom Action 5: PRESS_TAB\n    - purpose: Press the TAB button.\n    - format: PRESS_TAB\n    - example usage: PRESS_TAB\n\nCustom Action 6: PRESS_ESC\n    - purpose: Press the ESC button.\n    - format: PRESS_ESC\n    - example usage: PRESS_ESC\n\nCustom Action 7: PRESS_PGDN\n    - purpose: Press the PGDN button.\n    - format: PRESS_PGDN\n    - example usage: PRESS_PGDN\n\nCustom Action 8: PRESS_DOWN\n    - purpose: Press the DOWN button.\n    - format: PRESS_DOWN\n    - example usage: PRESS_DOWN\n\nCustom Action 9: PRESS_ENTER\n    - purpose: Press the ENTER button.\n    - format: PRESS_ENTER\n    - example usage: PRESS_ENTER\n\nCustom Action 10: PRESS_RIGHT\n    - purpose: Press the RIGHT button.\n    - format: PRESS_RIGHT\n    - example usage: PRESS_RIGHT\n\nCustom Action 10: HOTKEY\n    - purpose: Use the hot key.\n    - format: HOTKEY [keys]\n    - example usage: HOTKEY [CTRL_A]\n\n\nIn most cases, task instructions are high-level and abstract. Carefully read the instruction and action history, then perform reasoning to determine the most appropriate next action. Ensure you strictly generate two sections: Thoughts and Actions.\nThoughts: Clearly outline your reasoning process for current step.\nActions: Specify the actual actions you will take based on your reasoning.\n\nYour current task instruction, action history, and associated screenshot are as follows:\nScreenshot: <image>\nTask: review the products added to the cart\nHistory: \nNone\n"}, {"from": "gpt", "value": "thoughts:\nreview the products added to the cart\nactions:\nCLICK <point>[[894,128]]</point>"}]}
{"id": 1, "image": "/cpfs01/user/wuzhenyu/InternVL/playground/raw_data/omniact/data/data/web/asics/screen1.png", "conversations": [{"from": "human", "value": "\nYou are a foundational action model capable of automating tasks across various digital environments, including desktop systems like Windows, macOS, and Linux, as well as mobile platforms such as Android and iOS. You also excel in web browser environments. You will interact with digital devices in a human-like manner: by reading screenshots, analyzing them, and taking appropriate actions.\n\nYour expertise covers two types of digital tasks:\n    - Grounding: Given a screenshot and a description, you assist users in locating elements mentioned. Sometimes, you must infer which elements best fit the description when they aren't explicitly stated.\n    - Executable Language Grounding: With a screenshot and task instruction, your goal is to determine the executable actions needed to complete the task.\n\n\nYou are now operating in Executable Language Grounding mode. Your goal is to help users accomplish tasks by suggesting executable actions that best fit their needs. Your skill set includes both basic and custom actions:\n\n1. Basic Actions\nBasic actions are standardized and available across all platforms. They provide essential functionality and are defined with a specific format, ensuring consistency and reliability. \nBasic Action 1: CLICK \n    - purpose: Click at the specified position.\n    - format: CLICK <point>[[x-axis, y-axis]]</point>\n    - example usage: CLICK <point>[[101, 872]]</point>\n       \nBasic Action 2: TYPE\n    - purpose: Enter specified text at the designated location.\n    - format: TYPE [input text]\n    - example usage: TYPE [Shanghai shopping mall]\n\nBasic Action 3: SCROLL\n    - purpose: Scroll in the specified direction.\n    - format: SCROLL [direction (UP/DOWN/LEFT/RIGHT)]\n    - example usage: SCROLL [UP]\n    \n2.Custom Actions\nCustom actions are unique to each user's platform and environment. They allow for flexibility and adaptability, enabling the model to support new and unseen actions defined by users. These actions extend the functionality of the basic set, making the model more versatile and capable of handling specific tasks.\n\n\nCustom Action 1: DOUBLECLICK \n    - purpose: Double click at the specified position.\n    - format: DOUBLECLICK <point>[[x-axis, y-axis]]</point>\n    - example usage: DOUBLECLICK <point>[[101,872]]</point>\n\nCustom Action 2: RIGHTCLICK \n    - purpose: Right click at the specified position.\n    - format: DOUBLECLICK <point>[[x-axis, y-axis]]</point>\n    - example usage: DOUBLECLICK <point>[[101,872]]</point>\n\nCustom Action 3: MOVETO \n    - purpose: Move to the specified position.\n    - format: MOVETO <point>[[x-axis, y-axis]]</point>\n    - example usage: MOVETO <point>[[101,872]]</point>\n\nCustom Action 4: PRESS_SPACE\n    - purpose: Press the SPACE button.\n    - format: PRESS_SPACE\n    - example usage: PRESS_SPACE\n\nCustom Action 5: PRESS_TAB\n    - purpose: Press the TAB button.\n    - format: PRESS_TAB\n    - example usage: PRESS_TAB\n\nCustom Action 6: PRESS_ESC\n    - purpose: Press the ESC button.\n    - format: PRESS_ESC\n    - example usage: PRESS_ESC\n\nCustom Action 7: PRESS_PGDN\n    - purpose: Press the PGDN button.\n    - format: PRESS_PGDN\n    - example usage: PRESS_PGDN\n\nCustom Action 8: PRESS_DOWN\n    - purpose: Press the DOWN button.\n    - format: PRESS_DOWN\n    - example usage: PRESS_DOWN\n\nCustom Action 9: PRESS_ENTER\n    - purpose: Press the ENTER button.\n    - format: PRESS_ENTER\n    - example usage: PRESS_ENTER\n\nCustom Action 10: PRESS_RIGHT\n    - purpose: Press the RIGHT button.\n    - format: PRESS_RIGHT\n    - example usage: PRESS_RIGHT\n\nCustom Action 10: HOTKEY\n    - purpose: Use the hot key.\n    - format: HOTKEY [keys]\n    - example usage: HOTKEY [CTRL_A]\n\n\nIn most cases, task instructions are high-level and abstract. Carefully read the instruction and action history, then perform reasoning to determine the most appropriate next action. Ensure you strictly generate two sections: Thoughts and Actions.\nThoughts: Clearly outline your reasoning process for current step.\nActions: Specify the actual actions you will take based on your reasoning.\n\nYour current task instruction, action history, and associated screenshot are as follows:\nScreenshot: <image>\nTask: inspect the items currently residing in the shopping basket\nHistory: \nNone\n"}, {"from": "gpt", "value": "thoughts:\ninspect the items currently residing in the shopping basket\nactions:\nCLICK <point>[[894,128]]</point>"}]}
{"id": 2, "image": "/cpfs01/user/wuzhenyu/InternVL/playground/raw_data/omniact/data/data/web/asics/screen1.png", "conversations": [{"from": "human", "value": "\nYou are a foundational action model capable of automating tasks across various digital environments, including desktop systems like Windows, macOS, and Linux, as well as mobile platforms such as Android and iOS. You also excel in web browser environments. You will interact with digital devices in a human-like manner: by reading screenshots, analyzing them, and taking appropriate actions.\n\nYour expertise covers two types of digital tasks:\n    - Grounding: Given a screenshot and a description, you assist users in locating elements mentioned. Sometimes, you must infer which elements best fit the description when they aren't explicitly stated.\n    - Executable Language Grounding: With a screenshot and task instruction, your goal is to determine the executable actions needed to complete the task.\n\n\nYou are now operating in Executable Language Grounding mode. Your goal is to help users accomplish tasks by suggesting executable actions that best fit their needs. Your skill set includes both basic and custom actions:\n\n1. Basic Actions\nBasic actions are standardized and available across all platforms. They provide essential functionality and are defined with a specific format, ensuring consistency and reliability. \nBasic Action 1: CLICK \n    - purpose: Click at the specified position.\n    - format: CLICK <point>[[x-axis, y-axis]]</point>\n    - example usage: CLICK <point>[[101, 872]]</point>\n       \nBasic Action 2: TYPE\n    - purpose: Enter specified text at the designated location.\n    - format: TYPE [input text]\n    - example usage: TYPE [Shanghai shopping mall]\n\nBasic Action 3: SCROLL\n    - purpose: Scroll in the specified direction.\n    - format: SCROLL [direction (UP/DOWN/LEFT/RIGHT)]\n    - example usage: SCROLL [UP]\n    \n2.Custom Actions\nCustom actions are unique to each user's platform and environment. They allow for flexibility and adaptability, enabling the model to support new and unseen actions defined by users. These actions extend the functionality of the basic set, making the model more versatile and capable of handling specific tasks.\n\n\nCustom Action 1: DOUBLECLICK \n    - purpose: Double click at the specified position.\n    - format: DOUBLECLICK <point>[[x-axis, y-axis]]</point>\n    - example usage: DOUBLECLICK <point>[[101,872]]</point>\n\nCustom Action 2: RIGHTCLICK \n    - purpose: Right click at the specified position.\n    - format: DOUBLECLICK <point>[[x-axis, y-axis]]</point>\n    - example usage: DOUBLECLICK <point>[[101,872]]</point>\n\nCustom Action 3: MOVETO \n    - purpose: Move to the specified position.\n    - format: MOVETO <point>[[x-axis, y-axis]]</point>\n    - example usage: MOVETO <point>[[101,872]]</point>\n\nCustom Action 4: PRESS_SPACE\n    - purpose: Press the SPACE button.\n    - format: PRESS_SPACE\n    - example usage: PRESS_SPACE\n\nCustom Action 5: PRESS_TAB\n    - purpose: Press the TAB button.\n    - format: PRESS_TAB\n    - example usage: PRESS_TAB\n\nCustom Action 6: PRESS_ESC\n    - purpose: Press the ESC button.\n    - format: PRESS_ESC\n    - example usage: PRESS_ESC\n\nCustom Action 7: PRESS_PGDN\n    - purpose: Press the PGDN button.\n    - format: PRESS_PGDN\n    - example usage: PRESS_PGDN\n\nCustom Action 8: PRESS_DOWN\n    - purpose: Press the DOWN button.\n    - format: PRESS_DOWN\n    - example usage: PRESS_DOWN\n\nCustom Action 9: PRESS_ENTER\n    - purpose: Press the ENTER button.\n    - format: PRESS_ENTER\n    - example usage: PRESS_ENTER\n\nCustom Action 10: PRESS_RIGHT\n    - purpose: Press the RIGHT button.\n    - format: PRESS_RIGHT\n    - example usage: PRESS_RIGHT\n\nCustom Action 10: HOTKEY\n    - purpose: Use the hot key.\n    - format: HOTKEY [keys]\n    - example usage: HOTKEY [CTRL_A]\n\n\nIn most cases, task instructions are high-level and abstract. Carefully read the instruction and action history, then perform reasoning to determine the most appropriate next action. Ensure you strictly generate two sections: Thoughts and Actions.\nThoughts: Clearly outline your reasoning process for current step.\nActions: Specify the actual actions you will take based on your reasoning.\n\nYour current task instruction, action history, and associated screenshot are as follows:\nScreenshot: <image>\nTask: examine the items that have been added to the shopping trolley so far\nHistory: \nNone\n"}, {"from": "gpt", "value": "thoughts:\nexamine the items that have been added to the shopping trolley so far\nactions:\nCLICK <point>[[894,128]]</point>"}]}
